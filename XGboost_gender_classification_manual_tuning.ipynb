{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Gender Classification using Manual Fucntion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XSLKnfNiFGhA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "03I4qe7SFGhE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('gender_classification_v7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "R5mBP-vgFGhH",
    "outputId": "50db0166-3c65-45c9-f95b-2d0575476487"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
       "0          1               11.8                 6.1          1          0   \n",
       "1          0               14.0                 5.4          0          0   \n",
       "2          0               11.8                 6.3          1          1   \n",
       "3          0               14.4                 6.1          0          1   \n",
       "4          1               13.5                 5.9          0          0   \n",
       "\n",
       "   lips_thin  distance_nose_to_lip_long  Male  \n",
       "0          1                          1     1  \n",
       "1          1                          0     0  \n",
       "2          1                          1     1  \n",
       "3          1                          1     1  \n",
       "4          0                          0     0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vDEluxBPFGhK"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Male', axis=1)\n",
    "y = df['Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_zxklStsFGhM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Lu9bnUFMFGhO"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try XGBoost with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "5HFOUyOrFGhR",
    "outputId": "fd2ccd62-9534-4c5d-91df-919d2c9edfc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WH3w6rwKFGhT"
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "train_pred = xgb_model.predict(X_train) #To check the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "8e_m37r9FGhW",
    "outputId": "64881fad-7a80-4574-e861-0b4605aedbf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is:\n",
      "0.9988571428571429\n",
      "---------------------------------\n",
      "Test Accuracy score is:\n",
      "0.9600266489007329\n",
      "---------------------------------\n",
      "Confusion matrix:\n",
      "[[711  28]\n",
      " [ 32 730]]\n",
      "---------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       739\n",
      "           1       0.96      0.96      0.96       762\n",
      "\n",
      "    accuracy                           0.96      1501\n",
      "   macro avg       0.96      0.96      0.96      1501\n",
      "weighted avg       0.96      0.96      0.96      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print('Train Accuracy score is:')\n",
    "print(accuracy_score(y_train, train_pred))\n",
    "print('---------------------------------')\n",
    "print('Test Accuracy score is:')\n",
    "print(accuracy_score(y_test, xgb_pred))\n",
    "print('---------------------------------')\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, xgb_pred))\n",
    "print('---------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_score():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    base_score = [x/100 for x in range(40,81)] # 4,4.1,....8\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in base_score:\n",
    "        xgb_model = XGBClassifier(base_score=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(base_score):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "base_score = base_score()\n",
    "base_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_depth():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    max_depth = [x for x in range(1,16)] # 1,2,...15\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in max_depth:\n",
    "        xgb_model = XGBClassifier(base_score=base_score, max_depth=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(max_depth):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "max_depth = max_depth()\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subsample():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    subsample = [x/100 for x in range(0,51)] # 0,0.01,0.02,....5.0\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in subsample:\n",
    "        xgb_model = XGBClassifier(base_score=base_score, max_depth=max_depth,subsample=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(subsample):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "subsample = subsample()\n",
    "subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n_estimators():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    n_estimators = [x for x in range(10,500,20)] # 10,30,50,....990\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in n_estimators:\n",
    "        xgb_model = XGBClassifier(base_score=base_score, max_depth=max_depth,\n",
    "                                  subsample=subsample,n_estimators=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(n_estimators):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "n_estimators = n_estimators()\n",
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def learning_rate():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    learning_rate = [x/100 for x in range(5,105,5)] # 0.05,0.01,....1.0\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in learning_rate:\n",
    "        xgb_model = XGBClassifier(base_score=base_score, max_depth=max_depth,\n",
    "                                  subsample=subsample,n_estimators=n_estimators,\n",
    "                                  learning_rate=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(learning_rate):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "learning_rate = learning_rate()\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_child_weight():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    min_child_weight = [x/10 for x in range(1,301)] # 0.1,0.2,....30.0\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in min_child_weight:\n",
    "        xgb_model = XGBClassifier(base_score=base_score, max_depth=max_depth,\n",
    "                                  subsample=subsample,n_estimators=n_estimators,\n",
    "                                  learning_rate=learning_rate,min_child_weight=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(min_child_weight):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "min_child_weight = min_child_weight()\n",
    "min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gamma():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    gamma = [x/10 for x in range(1,101)] # 0.1,0.2,....10.0\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in gamma:\n",
    "        xgb_model = XGBClassifier(base_score=base_score, max_depth=max_depth,\n",
    "                                  subsample=subsample,n_estimators=n_estimators,\n",
    "                                  learning_rate=learning_rate,min_child_weight=min_child_weight,\n",
    "                                  gamma=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(gamma):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "gamma = gamma()\n",
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def colsample_bytree():\n",
    "    warn = 'The BEST VALUE is reaching the highest given parameter. You may alter the parameter for better performance.'\n",
    "    colsample_bytree = [x/100 for x in range(0,101)] # 0.01,0.02,....1.0\n",
    "    max_test_acc = 0\n",
    "    best_value = 0\n",
    "    for value in colsample_bytree:\n",
    "        xgb_model = XGBClassifier(base_score=base_score, max_depth=max_depth,\n",
    "                                  subsample=subsample,n_estimators=n_estimators,\n",
    "                                  learning_rate=learning_rate,min_child_weight=min_child_weight,\n",
    "                                  gamma=gamma,colsample_bytree=value)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        xgb_pred = xgb_model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "        if test_accuracy > max_test_acc:\n",
    "            max_test_acc = test_accuracy\n",
    "            best_value = value\n",
    "    if best_value == max(colsample_bytree):\n",
    "        print(warn)\n",
    "    return best_value\n",
    "\n",
    "colsample_bytree = colsample_bytree()\n",
    "colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_score:  0.49\n",
      "colsample_bytree:  0.0\n",
      "gamma:  0.1\n",
      "learning_rate:  0.9\n",
      "max_depth:  1\n",
      "min_child_weight:  0.1\n",
      "n_estimators:  30\n",
      "subsample:  0.4\n"
     ]
    }
   ],
   "source": [
    "print('base_score: ', base_score)\n",
    "print('colsample_bytree: ', colsample_bytree)\n",
    "print('gamma: ', gamma)\n",
    "print('learning_rate: ', learning_rate)\n",
    "print('max_depth: ', max_depth)\n",
    "print('min_child_weight: ', min_child_weight)\n",
    "print('n_estimators: ', n_estimators)\n",
    "print('subsample: ', subsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_xgb_model():\n",
    "    xgb_model = XGBClassifier(base_score=base_score,colsample_bytree=colsample_bytree,\n",
    "                                  gamma=gamma,learning_rate=learning_rate,\n",
    "                                  max_depth=max_depth,min_child_weight=min_child_weight,\n",
    "                                  n_estimators=n_estimators,subsample=subsample)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    train_pred = xgb_model.predict(X_train)\n",
    "    return train_pred, xgb_pred\n",
    "\n",
    "best_xgb_model()\n",
    "train_pred = best_xgb_model()[0]\n",
    "xgb_pred = best_xgb_model()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score is:\n",
      "0.9771428571428571\n",
      "---------------------------------\n",
      "Test Accuracy score is:\n",
      "0.972018654230513\n",
      "---------------------------------\n",
      "Confusion matrix:\n",
      "[[728  11]\n",
      " [ 31 731]]\n",
      "---------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       739\n",
      "           1       0.99      0.96      0.97       762\n",
      "\n",
      "    accuracy                           0.97      1501\n",
      "   macro avg       0.97      0.97      0.97      1501\n",
      "weighted avg       0.97      0.97      0.97      1501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy score is:')\n",
    "print(accuracy_score(y_train, train_pred))\n",
    "print('---------------------------------')\n",
    "print('Test Accuracy score is:')\n",
    "print(accuracy_score(y_test, xgb_pred))\n",
    "print('---------------------------------')\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test, xgb_pred))\n",
    "print('---------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "XGboost_Iris_Flower.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
